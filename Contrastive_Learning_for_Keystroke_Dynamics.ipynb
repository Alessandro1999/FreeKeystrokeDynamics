{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alessandro1999/FreeKeystrokeDynamics/blob/main/Contrastive_Learning_for_Keystroke_Dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWLAbFwGhxyL"
      },
      "source": [
        "# Contrastive learning for Keystroke Dynamics\n",
        "by Alessandro Torri.\n",
        "\n",
        "\n",
        "The purpose of this project is to train a Pytorch model with contrastive learning to obtain a feature representation of free-text keystroke dynamics, and then use this model to implement a verification system.\n",
        "The idea of the project is strongly inspired by this [paper](https://arxiv.org/pdf/2004.03627.pdf), with the objective of improving their results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeOJM1oapywQ"
      },
      "source": [
        "##0. Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pxFNHmF9lBFT"
      },
      "outputs": [],
      "source": [
        "#@title Downloading libraries\n",
        "!pip -q install pytorch-lightning\n",
        "!pip -q install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YOwar6WHpQQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be48465-cd0a-4da3-9c75-968dcda0df77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#@title Import libraries\n",
        "# general libraries\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import *\n",
        "from google.colab import drive\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "# ml libraries\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn import model_selection\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import callbacks\n",
        "import wandb\n",
        "# for scraping of js keycodes\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "seed = 17\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FLLN_MCSqWtd"
      },
      "outputs": [],
      "source": [
        "#@title Hyperparameters\n",
        "#@markdown Number of batches per epoch to consider\n",
        "train_batches_per_epoch: int = 150 #@param{type: \"integer\"}\n",
        "#@markdown Size of a batch\n",
        "batch_size: int = 128 #@param{type: \"integer\"}\n",
        "#@markdown Name of the Weights & Biases run\n",
        "run_name: str = \"Transformer(alpha2)\" #@param{type : \"string\"}\n",
        "#@markdown Number of subject in the training set\n",
        "train_size : int = 68000 #@param{type: \"integer\"}\n",
        "#@markdown Percentage of users of the training set to use for validation\n",
        "perc: float = 0.000397 #@param{type: \"number\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BhsG2suiOhb"
      },
      "source": [
        "##1. The dataset\n",
        "The [dataset](https://userinterfaces.aalto.fi/136Mkeystrokes/) that will be used to train our model contains 15 sentences written by 168K different users with the modalities described in the following [paper](https://userinterfaces.aalto.fi/136Mkeystrokes/resources/chi-18-analysis.pdf).\n",
        "\n",
        "The dataset consists of a .csv (tab separated) file for each user in which every line is a key typed event.\n",
        "This representation wastes a lot of space and it also makes it more difficult to extrapolate a sequence from the dataframe.\n",
        "For this reason, the first thing I did was to preprocess this dataset and format it such that it has a line for each sequence typed by the user.\n",
        "This formatting operation reduced the size of the dataset from 16GB to 3GB and it makes it easier to be used.\n",
        "\n",
        "However, considering the big size of the dataset, formatting it in python was really really slow, so I decided to do it using the Julia language and the code used to do that can be found in the following [notebook](https://colab.research.google.com/drive/1yrVAJRK3cgsgGTrXojRrs7v5Gfapffpf).\n",
        "\n",
        "So, as a first thing to do, we will download and unzip our dataset from the public drive link where I uploaded it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS52WOjyOlX-",
        "outputId": "1986281a-aab6-43ee-949b-d8a486666193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 16:46:39--  https://docs.google.com/uc?export=download&confirm=t&id=1yg8zcON6zyu90VCuEvVM8W9yg8Lk9olb\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.127.139, 108.177.127.138, 108.177.127.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.127.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ndli3ed25f7910b5nluqvcrhtbkao4h7/1674751575000/05640747438315365327/*/1yg8zcON6zyu90VCuEvVM8W9yg8Lk9olb?e=download&uuid=68a82a80-bc8e-459b-93e4-635703b8e76f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-01-26 16:46:40--  https://doc-0g-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ndli3ed25f7910b5nluqvcrhtbkao4h7/1674751575000/05640747438315365327/*/1yg8zcON6zyu90VCuEvVM8W9yg8Lk9olb?e=download&uuid=68a82a80-bc8e-459b-93e4-635703b8e76f\n",
            "Resolving doc-0g-cc-docs.googleusercontent.com (doc-0g-cc-docs.googleusercontent.com)... 142.251.31.132, 2a00:1450:4013:c1a::84\n",
            "Connecting to doc-0g-cc-docs.googleusercontent.com (doc-0g-cc-docs.googleusercontent.com)|142.251.31.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 773884511 (738M) [application/zip]\n",
            "Saving to: ‘Keystrokes_processed.zip’\n",
            "\n",
            "Keystrokes_processe 100%[===================>] 738.03M   194MB/s    in 3.6s    \n",
            "\n",
            "2023-01-26 16:46:44 (202 MB/s) - ‘Keystrokes_processed.zip’ saved [773884511/773884511]\n",
            "\n",
            "replace data/Keystrokes_processed/481405_keystrokes.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/Keystrokes_processed/266467_keystrokes.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "a\n",
            "y\n"
          ]
        }
      ],
      "source": [
        "#@title Download the dataset\n",
        "!rm -rf sample_data\n",
        "#!gdown \"https://drive.google.com/uc?id=1yg8zcON6zyu90VCuEvVM8W9yg8Lk9olb\"\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1yg8zcON6zyu90VCuEvVM8W9yg8Lk9olb' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1yg8zcON6zyu90VCuEvVM8W9yg8Lk9olb\" -O Keystrokes_processed.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q Keystrokes_processed.zip\n",
        "!rm Keystrokes_processed.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD0bmEN6oCCp"
      },
      "source": [
        "### Data visualization\n",
        "Now that we obtained the dataset, we can see how it is made up. Indeed, we have a file for each user, and in each file we have stored the timing informations of the sentences he/she has typed.\n",
        "Each user has a unique ID, and (as we said) each row of the user file consists of a sequence typed. The columns of our files are the following:\n",
        "\n",
        "- PARTICIPANT_ID: The unique id of the user typing;\n",
        "- TEST_SECTION_ID: The unique id of the sentence shown to the user;\n",
        "- SENTENCE: Sentence shown to the user;\n",
        "- USER_INPUT: Sentence typed by the user after pressing Enter or Next button;\n",
        "- TIMINGS: An ordered list of tuple (key,keycode,dwell_time,waiting_time) with 4 elements, where each tuple represents the event of a key press/release with its timing informations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNh77wfnTqFd"
      },
      "outputs": [],
      "source": [
        "column_names = ['PARTICIPANT_ID','TEST_SECTION_ID','SENTENCE','USER_INPUT','TIMINGS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nGFcjPKgoezq",
        "outputId": "ed05202f-dd25-4380-dc52-f2847adc094a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    PARTICIPANT_ID  TEST_SECTION_ID  \\\n",
              "0           306610          3297345   \n",
              "1           306610          3297487   \n",
              "2           306610          3297580   \n",
              "3           306610          3297600   \n",
              "4           306610          3297318   \n",
              "5           306610          3297516   \n",
              "6           306610          3297458   \n",
              "7           306610          3297637   \n",
              "8           306610          3297410   \n",
              "9           306610          3297653   \n",
              "10          306610          3297251   \n",
              "11          306610          3297688   \n",
              "12          306610          3297372   \n",
              "13          306610          3297274   \n",
              "14          306610          3297543   \n",
              "\n",
              "                                             SENTENCE  \\\n",
              "0                I didn't hear from Ginger this week.   \n",
              "1          We haven't made that decision here though.   \n",
              "2   The team mate says were not interested at this...   \n",
              "3   But both reports were denied by the southern l...   \n",
              "4       Can you rough out a slide on rating agencies?   \n",
              "5       Hours are listed in 24hr format central time.   \n",
              "6          The film will be shown for the first time.   \n",
              "7                    Now go get washed up for dinner.   \n",
              "8   There are differing views among the dissident ...   \n",
              "9   Juntao is in Washington this week  meeting wit...   \n",
              "10         Drop him if he was on your Fantasy roster.   \n",
              "11      This year I can walk and it's so much better.   \n",
              "12           We want a little May madness of our own.   \n",
              "13  I'm not close enough right now to the discussion.   \n",
              "14        We will have some good detail by January 7.   \n",
              "\n",
              "                                           USER_INPUT  \\\n",
              "0               L didn't hear from Ginger this week.    \n",
              "1          We haven't made that decision here though.   \n",
              "2   The team mate says were not interested at this...   \n",
              "3   But both reports were denied by the southern l...   \n",
              "4       Can you rough out a slide on rating agencies?   \n",
              "5       Hours are listed in 24hr format central time.   \n",
              "6          The film will be shown for the first time.   \n",
              "7                     No go get washed up for dinner.   \n",
              "8   There are differin views among the dissiedent ...   \n",
              "9   Jantao is in Washington this week  meeting wit...   \n",
              "10         Drop him if he was in your Fantasy roster.   \n",
              "11      This year L can walk and it's so much better.   \n",
              "12           We want a little May madness of our own.   \n",
              "13  I'm not close enough right now to the discussion.   \n",
              "14        we will have some good detail by January 7.   \n",
              "\n",
              "                                              TIMINGS  \n",
              "0   Any[(\"SHIFT\", 16, 431, 0), (\"76\", missing, 158...  \n",
              "1   Any[(\"SHIFT\", 16, 426, 0), (\"87\", missing, 197...  \n",
              "2   Any[(\"SHIFT\", 16, 348, 0), (\"84\", missing, 160...  \n",
              "3   Any[(\"SHIFT\", 16, 463, 0), (\"66\", missing, 196...  \n",
              "4   Any[(\"SHIFT\", 16, 116, 0), (\"SHIFT\", 16, 456, ...  \n",
              "5   Any[(\"SHIFT\", 16, 272, 0), (\"72\", missing, 121...  \n",
              "6   Any[(\"SHIFT\", 16, 234, 0), (\"84\", missing, 121...  \n",
              "7   Any[(\"SHIFT\", 16, 195, 0), (\"SHIFT\", 16, 437, ...  \n",
              "8   Any[(\"SHIFT\", 16, 319, 0), (\"84\", missing, 159...  \n",
              "9   Any[(\"SHIFT\", 16, 311, 0), (\"74\", missing, 159...  \n",
              "10  Any[(\"SHIFT\", 16, 263, 0), (\"68\", missing, 229...  \n",
              "11  Any[(\"SHIFT\", 16, 278, 0), (\"84\", missing, 119...  \n",
              "12  Any[(\"SHIFT\", 16, 348, 0), (\"87\", missing, 159...  \n",
              "13  Any[(\"SHIFT\", 16, 1260, 0), (\"59\", missing, 23...  \n",
              "14  Any[(\"87\", missing, 157, 0), (\"69\", missing, 1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd9609f0-6dbe-46de-9e92-6eb4dd9c2aaf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PARTICIPANT_ID</th>\n",
              "      <th>TEST_SECTION_ID</th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>USER_INPUT</th>\n",
              "      <th>TIMINGS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297345</td>\n",
              "      <td>I didn't hear from Ginger this week.</td>\n",
              "      <td>L didn't hear from Ginger this week.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 431, 0), (\"76\", missing, 158...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297487</td>\n",
              "      <td>We haven't made that decision here though.</td>\n",
              "      <td>We haven't made that decision here though.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 426, 0), (\"87\", missing, 197...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297580</td>\n",
              "      <td>The team mate says were not interested at this...</td>\n",
              "      <td>The team mate says were not interested at this...</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 348, 0), (\"84\", missing, 160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297600</td>\n",
              "      <td>But both reports were denied by the southern l...</td>\n",
              "      <td>But both reports were denied by the southern l...</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 463, 0), (\"66\", missing, 196...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297318</td>\n",
              "      <td>Can you rough out a slide on rating agencies?</td>\n",
              "      <td>Can you rough out a slide on rating agencies?</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 116, 0), (\"SHIFT\", 16, 456, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297516</td>\n",
              "      <td>Hours are listed in 24hr format central time.</td>\n",
              "      <td>Hours are listed in 24hr format central time.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 272, 0), (\"72\", missing, 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297458</td>\n",
              "      <td>The film will be shown for the first time.</td>\n",
              "      <td>The film will be shown for the first time.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 234, 0), (\"84\", missing, 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297637</td>\n",
              "      <td>Now go get washed up for dinner.</td>\n",
              "      <td>No go get washed up for dinner.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 195, 0), (\"SHIFT\", 16, 437, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297410</td>\n",
              "      <td>There are differing views among the dissident ...</td>\n",
              "      <td>There are differin views among the dissiedent ...</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 319, 0), (\"84\", missing, 159...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297653</td>\n",
              "      <td>Juntao is in Washington this week  meeting wit...</td>\n",
              "      <td>Jantao is in Washington this week  meeting wit...</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 311, 0), (\"74\", missing, 159...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297251</td>\n",
              "      <td>Drop him if he was on your Fantasy roster.</td>\n",
              "      <td>Drop him if he was in your Fantasy roster.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 263, 0), (\"68\", missing, 229...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297688</td>\n",
              "      <td>This year I can walk and it's so much better.</td>\n",
              "      <td>This year L can walk and it's so much better.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 278, 0), (\"84\", missing, 119...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297372</td>\n",
              "      <td>We want a little May madness of our own.</td>\n",
              "      <td>We want a little May madness of our own.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 348, 0), (\"87\", missing, 159...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297274</td>\n",
              "      <td>I'm not close enough right now to the discussion.</td>\n",
              "      <td>I'm not close enough right now to the discussion.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 1260, 0), (\"59\", missing, 23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297543</td>\n",
              "      <td>We will have some good detail by January 7.</td>\n",
              "      <td>we will have some good detail by January 7.</td>\n",
              "      <td>Any[(\"87\", missing, 157, 0), (\"69\", missing, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd9609f0-6dbe-46de-9e92-6eb4dd9c2aaf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd9609f0-6dbe-46de-9e92-6eb4dd9c2aaf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd9609f0-6dbe-46de-9e92-6eb4dd9c2aaf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#@title Visualize data of a specific user {run:\"auto\"}\n",
        "id: int = 306610 #@param{type:\"integer\"}\n",
        "df: pd.DataFrame = None\n",
        "try:\n",
        "    df : pd.DataFrame = pd.read_csv(f\"data/Keystrokes_processed/{id}_keystrokes.txt\",\n",
        "                                sep=\",\",\n",
        "                                names = column_names,\n",
        "                                header=None,\n",
        "                                encoding = \"ISO-8859-1\",\n",
        "                                )\n",
        "except FileNotFoundError:\n",
        "    print(f\"There is no user with id = {id}\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm81XjjS20MP"
      },
      "source": [
        "##2. Data preprocessing\n",
        "\n",
        "As we have seen from the dataframe visualization example before, the TIMINGS column looks a bit weird; this is because we preprocessed the dataset using Julia and we saved it into .csv files using the Julia CSV package. Basically, our TIMINGS column is a string that represents a Julia list of tuples.\n",
        "\n",
        "However, our goal in this section is to convert this string into an actual python list of tuples, so that we can easily manipulate our data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfR97VN4yhIm"
      },
      "source": [
        "### Javascript keycode mapping\n",
        "The dataset we are analyzing has been obtained with JavaScript, and in the readme file of the dataset it says that for some event they weren't able to capture the key that was pressed/released; however, they were anyway able to get the JavaScript keycode of the key. So, if someone wants to get the key from the keycode should use the Javascript keycodes.\n",
        "\n",
        "Unfortunately, python keycodes are different from the JavaScript ones, so to obtain a proper mapping, what we are going to do is to retrieve the keycodes informations from this nice [website](https://xoax.net/sub_javascript/ref_core/apx_key_code_table/) and store them in a json object (in case the website is no longer available in the future).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t51NjFCrkMXo",
        "outputId": "f0ef2e6b-4d68-4289-ee76-57382a418e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 17:07:40--  https://docs.google.com/uc?export=download&confirm=&id=1AyNVrmuumAuJFRhc54iWX1zB0znwoGub\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.127.138, 108.177.127.100, 108.177.127.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.127.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/465kkvkbeb0rveli7om8uj1dv04eq47e/1674752850000/05640747438315365327/*/1AyNVrmuumAuJFRhc54iWX1zB0znwoGub?e=download&uuid=03b3f211-d0ba-46c4-97b5-4765cbc412a2 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-01-26 17:07:40--  https://doc-14-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/465kkvkbeb0rveli7om8uj1dv04eq47e/1674752850000/05640747438315365327/*/1AyNVrmuumAuJFRhc54iWX1zB0znwoGub?e=download&uuid=03b3f211-d0ba-46c4-97b5-4765cbc412a2\n",
            "Resolving doc-14-cc-docs.googleusercontent.com (doc-14-cc-docs.googleusercontent.com)... 142.251.31.132, 2a00:1450:4013:c1a::84\n",
            "Connecting to doc-14-cc-docs.googleusercontent.com (doc-14-cc-docs.googleusercontent.com)|142.251.31.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3526 (3.4K) [application/json]\n",
            "Saving to: ‘keycodes.json’\n",
            "\n",
            "keycodes.json       100%[===================>]   3.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 17:07:40 (57.1 MB/s) - ‘keycodes.json’ saved [3526/3526]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Obtain the Javascript keycode mappings\n",
        "# download the mapping from google drive\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1AyNVrmuumAuJFRhc54iWX1zB0znwoGub' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1AyNVrmuumAuJFRhc54iWX1zB0znwoGub\" -O keycodes.json && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# load the json object and sort it\n",
        "with open(\"keycodes.json\", \"r\") as kc:\n",
        "    js_code_to_key : Dict[int, List[str]] = json.load(kc)\n",
        "js_code_to_key = { int(code): (key if type(key) != list else sorted([ k.lower() for k in key], key=lambda x: (len(x),not(x.isalpha()),x))) for code,key in js_code_to_key.items() }\n",
        "\n",
        "\n",
        "# obtain the reverse mapping\n",
        "js_key_to_code : Dict[str,List[int]] = dict()\n",
        "for keycode, keys in js_code_to_key.items():\n",
        "    if type(keys) == list:\n",
        "        for key in keys:\n",
        "            js_key_to_code[key] = js_key_to_code.get(key,set()) | {keycode}\n",
        "    else:\n",
        "        js_key_to_code[keys] = js_key_to_code.get(keys,set()) | {keycode}\n",
        "\n",
        "for key in js_key_to_code:\n",
        "    if len(js_key_to_code[key]) == 1:\n",
        "        js_key_to_code[key] = list(js_key_to_code[key])[0]\n",
        "    else:\n",
        "        js_key_to_code[key] = list(js_key_to_code[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UICOtnEfOBLp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c549fc3c-b402-4b69-9369-f16bdbc8425d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\njs_code_to_key[59] = \";\"\\njs_code_to_key[173] = \"-\"\\njs_code_to_key[170] = \"Backslash\"\\njs_code_to_key[171] = \"*\"\\njs_code_to_key[160] = \"ì\"\\njs_code_to_key[61] = \"=\"\\njs_code_to_key[163] = \"#\"\\njs_code_to_key[63] = \"?\"\\njs_code_to_key[58] = \".\"\\njs_code_to_key[64] = \"@\"\\njs_code_to_key[60] = \"<\"\\t\\njs_code_to_key[161] = \"^\"\\njs_code_to_key[162] = \"¢\"\\njs_code_to_key[164] = \"$\"\\t\\njs_code_to_key[165] = \"ù\"\\njs_code_to_key[166] = \"BrowserBack\"\\njs_code_to_key[167] = \"BrowserForward\"\\njs_code_to_key[168] = \"BrowserRefresh\"\\njs_code_to_key[169] = \")\"\\njs_code_to_key[172] = \"|\"\\njs_code_to_key[174] = \"AudioVolumeDown\"\\njs_code_to_key[175] = \"AudioVolumeUp\"\\njs_code_to_key[0] = \"Unidentified\"\\njs_key_to_code[\"BKSP\"] = 8\\n\\n\\nfor code,key in js_code_to_key.items():\\n    if key not in js_key_to_code:\\n        js_key_to_code[key] = code\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#@title Hotfix on missing values (DEPRECATED)\n",
        "'''\n",
        "js_code_to_key[59] = \";\"\n",
        "js_code_to_key[173] = \"-\"\n",
        "js_code_to_key[170] = \"Backslash\"\n",
        "js_code_to_key[171] = \"*\"\n",
        "js_code_to_key[160] = \"ì\"\n",
        "js_code_to_key[61] = \"=\"\n",
        "js_code_to_key[163] = \"#\"\n",
        "js_code_to_key[63] = \"?\"\n",
        "js_code_to_key[58] = \".\"\n",
        "js_code_to_key[64] = \"@\"\n",
        "js_code_to_key[60] = \"<\"\t\n",
        "js_code_to_key[161] = \"^\"\n",
        "js_code_to_key[162] = \"¢\"\n",
        "js_code_to_key[164] = \"$\"\t\n",
        "js_code_to_key[165] = \"ù\"\n",
        "js_code_to_key[166] = \"BrowserBack\"\n",
        "js_code_to_key[167] = \"BrowserForward\"\n",
        "js_code_to_key[168] = \"BrowserRefresh\"\n",
        "js_code_to_key[169] = \")\"\n",
        "js_code_to_key[172] = \"|\"\n",
        "js_code_to_key[174] = \"AudioVolumeDown\"\n",
        "js_code_to_key[175] = \"AudioVolumeUp\"\n",
        "js_code_to_key[0] = \"Unidentified\"\n",
        "js_key_to_code[\"BKSP\"] = 8\n",
        "\n",
        "\n",
        "for code,key in js_code_to_key.items():\n",
        "    if key not in js_key_to_code:\n",
        "        js_key_to_code[key] = code\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R78t4-Sygc0g"
      },
      "source": [
        "### Conversion of the TIMINGS column\n",
        "As described in the introduction of this section, we want to convert the TIMINGS column of our dataset from a string to a python list of tuples.\n",
        "\n",
        "We will use regular expressions (regex) to find the matches of the tuple in the TIMINGS strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjxFSXIsaYPr"
      },
      "outputs": [],
      "source": [
        "#@title Regex and function to convert a TIMING string into a python list\n",
        "\n",
        "# this set will contain all the characters used in typing (for the training set)\n",
        "chars : Set[str] = set()\n",
        "\n",
        "# the regex that identifies a tuple (key,keycode,dt,wt)\n",
        "regex = r\"\\(\\\"(\\w+|\\s|\\W|\\\\\\w)\\\", (\\d+|missing), \\d+(\\.\\d+)?, \\-?\\d+(.\\d+)?\\)\"\n",
        "\n",
        "# the regex to identify (for manual data) triple (char,press time, release time)\n",
        "manual_regex: str = r\"\\(((\\<\\S+\\: ((\\' \\')|\\<\\d+\\>)\\>)|(\\'\\S\\'|\\\"\\'\\\"))\\, \\d+\\.\\d+\\, \\d+\\.\\d+\\)\"\n",
        "\n",
        "# the actual function that makes the conversion\n",
        "def string_to_timings(s : str) -> List[Tuple[str,int,float,float]]:\n",
        "    '''\n",
        "    Given a string representing the TIMING cell of a row in the dataframe,\n",
        "    this function process this string and formats that into a list of tuple,\n",
        "    where each of them has:\n",
        "        - key, str reperesentation of the key pressed;\n",
        "        - keycode, javascript keycode of the key pressed;\n",
        "        - dwell time, elapsed time between key press and key release;\n",
        "        - waiting time, elapsed time between the previous key press and the actual key release.\n",
        "    '''\n",
        "    out : List[Tuple[str,int,float,float]] = list()\n",
        "    for match in re.finditer(regex, s, re.MULTILINE):\n",
        "        key, keycode, dt, wt = match.group()[1:-1].split(\", \")\n",
        "        key = key[1:-1] # remove \" at the beginning and \" at the end\n",
        "        if keycode == \"missing\":\n",
        "            keycode = key\n",
        "            key = js_code_to_key[int(key)]\n",
        "            if type(key) == list:\n",
        "                key = key[0]\n",
        "        elif key == \"\\\\b\": #TODO (?)\n",
        "            key = \"backspace\"\n",
        "        chars.add(key.lower())\n",
        "        out.append((key.lower(),int(keycode),float(dt),float(wt)))\n",
        "    return out\n",
        "\n",
        "def string_to_vocab(s : str) -> None:\n",
        "    '''\n",
        "    Given a representing the TIMING cell of a row in the dataframe,\n",
        "    this functions adds all the typed characters in a set called \"chars\"\n",
        "    '''\n",
        "    for match_found in re.finditer(regex, s, re.MULTILINE):\n",
        "        key, keycode, dt, wt = match_found.group()[1:-1].split(\", \")\n",
        "        key = key[1:-1] # remove \" at the beginning and \" at the end\n",
        "        if keycode == \"missing\":\n",
        "            key = js_code_to_key[int(key)]\n",
        "            if type(key) == list:\n",
        "                key = key[0]\n",
        "        elif key == \"\\\\b\":\n",
        "            key = \"backspace\"\n",
        "        chars.add(key.lower())\n",
        "\n",
        "\n",
        "def string_to_tensor(s : str, vocab : Dict[str,int]) -> torch.Tensor:\n",
        "    '''\n",
        "    Given a representing the TIMING cell of a row in the dataframe,\n",
        "    this functions transforms the row into a tensor where the keys\n",
        "    are mapped to indices according to the vocab mapping\n",
        "    '''\n",
        "    out : List[Tuple[int,float,float]] = list()\n",
        "    for match in re.finditer(regex, s, re.MULTILINE):\n",
        "        key, keycode, dt, wt = match.group()[1:-1].split(\", \")\n",
        "        key = key[1:-1] # remove \" at the beginning and \" at the end\n",
        "        if keycode == \"missing\":\n",
        "            keycode = key\n",
        "            key = js_code_to_key[int(key)]\n",
        "            if type(key) == list:\n",
        "                key = key[0]\n",
        "        elif key == \"\\\\b\": #TODO (?)\n",
        "            key = \"backspace\"\n",
        "        out.append((vocab.get(key.lower(),vocab[UNK_KEY]),float(dt),float(wt)))\n",
        "    return torch.tensor(out)\n",
        "\n",
        "def string_to_seq(input: str) -> List[Tuple[str, float, float]]:\n",
        "    '''\n",
        "    Given an input string representing the recordings of a sentence,\n",
        "    this function returns it as a list of key,Dwell time for each key pressed\n",
        "    '''\n",
        "    matches = re.finditer(manual_regex, input, re.MULTILINE)\n",
        "    out = []\n",
        "    for match in matches:\n",
        "        key, press_time, release_time = match.group()[1:-1].split(\", \")\n",
        "        out.append((key[1:-1],\n",
        "                    round(float(press_time), 5),\n",
        "                    round(float(release_time), 5)))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0BQcYJmwY1Ol",
        "outputId": "f41040c0-2675-4c9d-a496-846bad830822"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    PARTICIPANT_ID  TEST_SECTION_ID  \\\n",
              "0           306610          3297345   \n",
              "1           306610          3297487   \n",
              "2           306610          3297580   \n",
              "3           306610          3297600   \n",
              "4           306610          3297318   \n",
              "5           306610          3297516   \n",
              "6           306610          3297458   \n",
              "7           306610          3297637   \n",
              "8           306610          3297410   \n",
              "9           306610          3297653   \n",
              "10          306610          3297251   \n",
              "11          306610          3297688   \n",
              "12          306610          3297372   \n",
              "13          306610          3297274   \n",
              "14          306610          3297543   \n",
              "\n",
              "                                             SENTENCE  \\\n",
              "0                I didn't hear from Ginger this week.   \n",
              "1          We haven't made that decision here though.   \n",
              "2   The team mate says were not interested at this...   \n",
              "3   But both reports were denied by the southern l...   \n",
              "4       Can you rough out a slide on rating agencies?   \n",
              "5       Hours are listed in 24hr format central time.   \n",
              "6          The film will be shown for the first time.   \n",
              "7                    Now go get washed up for dinner.   \n",
              "8   There are differing views among the dissident ...   \n",
              "9   Juntao is in Washington this week  meeting wit...   \n",
              "10         Drop him if he was on your Fantasy roster.   \n",
              "11      This year I can walk and it's so much better.   \n",
              "12           We want a little May madness of our own.   \n",
              "13  I'm not close enough right now to the discussion.   \n",
              "14        We will have some good detail by January 7.   \n",
              "\n",
              "                                           USER_INPUT  \\\n",
              "0               L didn't hear from Ginger this week.    \n",
              "1          We haven't made that decision here though.   \n",
              "2   The team mate says were not interested at this...   \n",
              "3   But both reports were denied by the southern l...   \n",
              "4       Can you rough out a slide on rating agencies?   \n",
              "5       Hours are listed in 24hr format central time.   \n",
              "6          The film will be shown for the first time.   \n",
              "7                     No go get washed up for dinner.   \n",
              "8   There are differin views among the dissiedent ...   \n",
              "9   Jantao is in Washington this week  meeting wit...   \n",
              "10         Drop him if he was in your Fantasy roster.   \n",
              "11      This year L can walk and it's so much better.   \n",
              "12           We want a little May madness of our own.   \n",
              "13  I'm not close enough right now to the discussion.   \n",
              "14        we will have some good detail by January 7.   \n",
              "\n",
              "                                              TIMINGS  \n",
              "0   [(shift, 16, 431.0, 0.0), (l, 76, 158.0, -164....  \n",
              "1   [(shift, 16, 426.0, 0.0), (w, 87, 197.0, -157....  \n",
              "2   [(shift, 16, 348.0, 0.0), (t, 84, 160.0, -119....  \n",
              "3   [(shift, 16, 463.0, 0.0), (b, 66, 196.0, 151.0...  \n",
              "4   [(shift, 16, 116.0, 0.0), (shift, 16, 456.0, 6...  \n",
              "5   [(shift, 16, 272.0, 0.0), (h, 72, 121.0, -80.0...  \n",
              "6   [(shift, 16, 234.0, 0.0), (t, 84, 121.0, -43.0...  \n",
              "7   [(shift, 16, 195.0, 0.0), (shift, 16, 437.0, 2...  \n",
              "8   [(shift, 16, 319.0, 0.0), (t, 84, 159.0, -119....  \n",
              "9   [(shift, 16, 311.0, 0.0), (j, 74, 159.0, -119....  \n",
              "10  [(shift, 16, 263.0, 0.0), (d, 68, 229.0, -151....  \n",
              "11  [(shift, 16, 278.0, 0.0), (t, 84, 119.0, -125....  \n",
              "12  [(shift, 16, 348.0, 0.0), (w, 87, 159.0, -81.0...  \n",
              "13  [(shift, 16, 1260.0, 0.0), (;, 59, 234.0, -312...  \n",
              "14  [(w, 87, 157.0, 0.0), (e, 69, 197.0, 75.0), ( ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d8d5f03-0902-403d-bb39-0257d71f7559\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PARTICIPANT_ID</th>\n",
              "      <th>TEST_SECTION_ID</th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>USER_INPUT</th>\n",
              "      <th>TIMINGS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297345</td>\n",
              "      <td>I didn't hear from Ginger this week.</td>\n",
              "      <td>L didn't hear from Ginger this week.</td>\n",
              "      <td>[(shift, 16, 431.0, 0.0), (l, 76, 158.0, -164....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297487</td>\n",
              "      <td>We haven't made that decision here though.</td>\n",
              "      <td>We haven't made that decision here though.</td>\n",
              "      <td>[(shift, 16, 426.0, 0.0), (w, 87, 197.0, -157....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297580</td>\n",
              "      <td>The team mate says were not interested at this...</td>\n",
              "      <td>The team mate says were not interested at this...</td>\n",
              "      <td>[(shift, 16, 348.0, 0.0), (t, 84, 160.0, -119....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297600</td>\n",
              "      <td>But both reports were denied by the southern l...</td>\n",
              "      <td>But both reports were denied by the southern l...</td>\n",
              "      <td>[(shift, 16, 463.0, 0.0), (b, 66, 196.0, 151.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297318</td>\n",
              "      <td>Can you rough out a slide on rating agencies?</td>\n",
              "      <td>Can you rough out a slide on rating agencies?</td>\n",
              "      <td>[(shift, 16, 116.0, 0.0), (shift, 16, 456.0, 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297516</td>\n",
              "      <td>Hours are listed in 24hr format central time.</td>\n",
              "      <td>Hours are listed in 24hr format central time.</td>\n",
              "      <td>[(shift, 16, 272.0, 0.0), (h, 72, 121.0, -80.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297458</td>\n",
              "      <td>The film will be shown for the first time.</td>\n",
              "      <td>The film will be shown for the first time.</td>\n",
              "      <td>[(shift, 16, 234.0, 0.0), (t, 84, 121.0, -43.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297637</td>\n",
              "      <td>Now go get washed up for dinner.</td>\n",
              "      <td>No go get washed up for dinner.</td>\n",
              "      <td>[(shift, 16, 195.0, 0.0), (shift, 16, 437.0, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297410</td>\n",
              "      <td>There are differing views among the dissident ...</td>\n",
              "      <td>There are differin views among the dissiedent ...</td>\n",
              "      <td>[(shift, 16, 319.0, 0.0), (t, 84, 159.0, -119....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297653</td>\n",
              "      <td>Juntao is in Washington this week  meeting wit...</td>\n",
              "      <td>Jantao is in Washington this week  meeting wit...</td>\n",
              "      <td>[(shift, 16, 311.0, 0.0), (j, 74, 159.0, -119....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297251</td>\n",
              "      <td>Drop him if he was on your Fantasy roster.</td>\n",
              "      <td>Drop him if he was in your Fantasy roster.</td>\n",
              "      <td>[(shift, 16, 263.0, 0.0), (d, 68, 229.0, -151....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297688</td>\n",
              "      <td>This year I can walk and it's so much better.</td>\n",
              "      <td>This year L can walk and it's so much better.</td>\n",
              "      <td>[(shift, 16, 278.0, 0.0), (t, 84, 119.0, -125....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297372</td>\n",
              "      <td>We want a little May madness of our own.</td>\n",
              "      <td>We want a little May madness of our own.</td>\n",
              "      <td>[(shift, 16, 348.0, 0.0), (w, 87, 159.0, -81.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297274</td>\n",
              "      <td>I'm not close enough right now to the discussion.</td>\n",
              "      <td>I'm not close enough right now to the discussion.</td>\n",
              "      <td>[(shift, 16, 1260.0, 0.0), (;, 59, 234.0, -312...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>306610</td>\n",
              "      <td>3297543</td>\n",
              "      <td>We will have some good detail by January 7.</td>\n",
              "      <td>we will have some good detail by January 7.</td>\n",
              "      <td>[(w, 87, 157.0, 0.0), (e, 69, 197.0, 75.0), ( ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d8d5f03-0902-403d-bb39-0257d71f7559')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d8d5f03-0902-403d-bb39-0257d71f7559 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d8d5f03-0902-403d-bb39-0257d71f7559');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#@title Example of a conversion\n",
        "\n",
        "# convert the TIMINGS column\n",
        "df.TIMINGS = df.TIMINGS.apply(string_to_timings)\n",
        "# show the updated dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q42a4zqOhaez"
      },
      "source": [
        "##3. Training, Validation and Test sets\n",
        "As the paper from which this work is inspired (TypeNet: Scaling up Keystroke Biometrics), we will train our model using just 68K users. Anyway, I'll add it as a tunable parameter of the notebook if one wants to change that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPVbPO-ShgcA",
        "outputId": "2b2cce33-230d-4b70-8c92-f8248270c482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68000/68000 [04:14<00:00, 267.28it/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Training dataset\n",
        "dataframes : List[pd.DataFrame] = list()\n",
        "users : List[str] = sorted(os.listdir(\"data/Keystrokes_processed/\"))\n",
        "added : int = 0\n",
        "idx : int = 0\n",
        "with tqdm(total=train_size) as pbar:\n",
        "    while added < train_size:\n",
        "        user = users[idx]\n",
        "        if \"keystrokes\" in user: # it is a user file (and not readme)\n",
        "            df : pd.DataFrame = pd.read_csv(f\"data/Keystrokes_processed/{user}\",\n",
        "                                        sep=\",\",\n",
        "                                        names = column_names,\n",
        "                                        header=None,\n",
        "                                        encoding = \"ISO-8859-1\",\n",
        "                                        )\n",
        "            dataframes.append(df)\n",
        "            added += 1\n",
        "            pbar.update(1)\n",
        "        idx += 1\n",
        "\n",
        "train_dataset : pd.DataFrame = pd.concat(dataframes)\n",
        "# for training we are not going to need these columns\n",
        "train_dataset = train_dataset.drop(['TEST_SECTION_ID','SENTENCE','USER_INPUT'],axis=1) \n",
        "del dataframes # let's free some RAM space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD6p2t-AOacY"
      },
      "source": [
        "Now, we will focus our dataset just to the two columns we need for the siamese training, that is the user id and his/her timings informations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "bOWBmXpolQHc",
        "outputId": "545218d5-7ca5-4757-f4cb-128381f12515"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  PARTICIPANT_ID                                            TIMINGS\n",
              "0         100001  Any[(\"SHIFT\", 16, 120, 0), (\"T\", 84, 128, -80)...\n",
              "1         100001  Any[(\"SHIFT\", 16, 144, 0), (\"I\", 73, 161, -89)...\n",
              "2         100001  Any[(\"SHIFT\", 16, 136, 0), (\"I\", 73, 152, -72)...\n",
              "3         100001  Any[(\"SHIFT\", 16, 136, 0), (\"P\", 80, 160, -104...\n",
              "4         100001  Any[(\"SHIFT\", 16, 103, 0), (\"C\", 67, 168, -56)..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b675389-2ed9-4b4e-868a-8cf66ae930dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PARTICIPANT_ID</th>\n",
              "      <th>TIMINGS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100001</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 120, 0), (\"T\", 84, 128, -80)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100001</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 144, 0), (\"I\", 73, 161, -89)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100001</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 136, 0), (\"I\", 73, 152, -72)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100001</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 136, 0), (\"P\", 80, 160, -104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100001</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 103, 0), (\"C\", 67, 168, -56)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b675389-2ed9-4b4e-868a-8cf66ae930dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b675389-2ed9-4b4e-868a-8cf66ae930dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b675389-2ed9-4b4e-868a-8cf66ae930dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LDehaIOI5RK"
      },
      "outputs": [],
      "source": [
        "#@title Train-Validation split\n",
        "\n",
        "# all the users of our dataset\n",
        "users: Set[str] = sorted(set(train_dataset.PARTICIPANT_ID))\n",
        "\n",
        "# the number of users we will keep in the training set\n",
        "train_num = int(len(users)*(1-perc))\n",
        "\n",
        "# sample the users at random\n",
        "training_users: Set[str] = random.sample(users, k=train_num)\n",
        "\n",
        "# the boolean series for the rows of the training dataframe\n",
        "train_series: pd.Series = train_dataset.PARTICIPANT_ID.isin(training_users)\n",
        "\n",
        "# the validation set is taken from the users not kept in the training set\n",
        "val_dataset: pd.DataFrame = train_dataset[~train_series]\n",
        "\n",
        "# the remaining users will be in our training set\n",
        "train_dataset = train_dataset[train_series]\n",
        "\n",
        "# split directly on the dataframe (I prefered to split the users to keep balanced the genuine and impostor pairs of the training)\n",
        "#train_dataset, val_dataset = model_selection.train_test_split(train_dataset, test_size=perc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-AAGQrFQOGp"
      },
      "source": [
        "After the split we can see how the data has been divided according to the given percentage and how the two dataframes have no rows in common:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYtOlnQWLPr1",
        "outputId": "a161c6b5-26d3-45e6-8f2b-bbf993637b9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1019580, 2), (405, 2), Empty DataFrame\n",
              " Columns: [PARTICIPANT_ID, TIMINGS]\n",
              " Index: [])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_dataset.shape, val_dataset.shape, pd.merge(train_dataset,val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYT5uZlXQZmY"
      },
      "outputs": [],
      "source": [
        "#@title Compute character vocabulary\n",
        "chars : Set[str] = set()\n",
        "train_dataset.TIMINGS.apply(string_to_vocab)\n",
        "# compute vocabulary only for the training set\n",
        "char_vocab : Dict[str,int] = { c:i+2 for i,c in enumerate(sorted(chars)) }\n",
        "UNK_KEY = \"<UNK>\"\n",
        "PAD_KEY = \"<PAD>\"\n",
        "char_vocab[PAD_KEY] = 0\n",
        "char_vocab[UNK_KEY] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYHZyA5JXbVK"
      },
      "source": [
        "##4. Pytorch pipeline\n",
        "\n",
        "Now we have all the necessary to move to the PyTorch framework and start training our Deep models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2KVi3oQDhWF"
      },
      "source": [
        "###4.1 Pytorch Dataset and Dataloader\n",
        "\n",
        "The first thing to do is to wrap our datasets into Pytorch Datasets:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oyIm8ILEZSC"
      },
      "source": [
        "####4.1.1. Siamese training\n",
        "Recall that our constrastive training will be a siamese training, meaning that each time we will give our model couples $(x_1,x_2)$ and we will train it to distinguish wheather $id(x_1) = id(x_2)$ or $id(x_1) \\neq id(x_2)$ ($id$ is the function that returns the identity of the input sample).\n",
        "\n",
        "This means that, if our dataset has $n$ sample, our siamese training will consist of $n \\choose 2$ = $\\frac{n(n-1)}{2}$ inputs to the model.\n",
        "\n",
        "However, we do not really want to have all the couples in memory, but we simply want to assign an index to each of them in order to distinguish them and implicitly represent them; In this way, we can generate the couples \"on the fly\" whenever they are requested.\n",
        "\n",
        "In the cell below I implemented the function that indexes all the possible couples of a generic list $[0,1,...,n-1]$ of n elements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Q5wNnIv5EYKN"
      },
      "outputs": [],
      "source": [
        "#@title Couples indexer function\n",
        "def index_2_combination(index: int, n: int, comb_num: int = None) -> Tuple[int, int]:\n",
        "    '''\n",
        "    Given the number of elements n (0,1,2,...,n-1) and an index i, this function returns\n",
        "    the index-th combinations with length 2 without repetition.\n",
        "    The combinations are ordered in ascending order.\n",
        "    '''\n",
        "    if comb_num is None:  # if not given, compute the number of possible couples\n",
        "        comb_num: int = n*(n-1)//2  # the number of combinations\n",
        "    cur_index = index + 1\n",
        "    assert (cur_index <= comb_num)  # assert you do not go out of index\n",
        "    first_e: int = 0  # the first element of the combination -> (0,?)\n",
        "    # while you can subtract by (n-e) it means that the index refers to a number > e\n",
        "    while cur_index - n + first_e + 1 > 0:\n",
        "        cur_index -= n - (first_e + 1)\n",
        "        first_e += 1\n",
        "    # the remainder gives us the second element\n",
        "    return first_e, (first_e + cur_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC51OvgYIEd1",
        "outputId": "79994521-bde1-45d9-cebe-ebdb717f1463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 1) (0, 3) (0, 4) (1, 3)\n"
          ]
        }
      ],
      "source": [
        "# example\n",
        "print(index_2_combination(0,5,10),index_2_combination(2,5,10), index_2_combination(3,5,10), index_2_combination(5,5,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH7Fvl8CIwbL"
      },
      "source": [
        "####4.1.2. First Dataset implementation\n",
        "Let's now create a simple implementation of our siamese Training with a PyTorch Dataset: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PJuRCNvnEDWJ"
      },
      "outputs": [],
      "source": [
        "#@title First implementation of the Dataset\n",
        "class SiameseDataset(torch.utils.data.Dataset):\n",
        "    '''\n",
        "    Dataset for the Siamese training of Keystroke Dynamics\n",
        "    '''\n",
        "    def __init__(self, df : pd.DataFrame, vocab : Dict[str,int]):\n",
        "        # the identities of the users\n",
        "        self.ground_truth : torch.Tensor = torch.tensor(list(df.PARTICIPANT_ID))\n",
        "        self.tot = self.ground_truth.shape[0] # number of samples\n",
        "        # we are doing siamese training, so the total n will be the possible couples\n",
        "        self.n = int((self.tot-1)*self.tot / 2) # number of combinations\n",
        "        # lengths and timings\n",
        "        self.lengths : torch.Tensor = torch.zeros_like(self.ground_truth)\n",
        "        strings = list(df.TIMINGS)\n",
        "        tensors : List[torch.Tensor] = list()\n",
        "        for i,string in tqdm(enumerate(strings),total = self.tot): # for every row of the dataset\n",
        "            tensors.append(string_to_tensor(string,vocab)) # convert the timings into tensors\n",
        "            self.lengths[i] = tensors[-1].shape[0] # get the lenght of the sequence\n",
        "        # pad the smaller sequences with 0's\n",
        "        self.timings : torch.Tensor = torch.nn.utils.rnn.pad_sequence(tensors,batch_first=True)\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return self.n\n",
        "    \n",
        "    def __getitem__(self,idx) ->Tuple[torch.Tensor]:\n",
        "        # convert the i-th element in the 2 indexes of the couple\n",
        "        idx1, idx2 = index_2_combination(idx,self.tot,self.n)\n",
        "        # return the data\n",
        "        return {\n",
        "                \"genuine\" : (self.ground_truth[idx1] == self.ground_truth[idx2]).long(),\n",
        "                \"timings1\": self.timings[idx1],\n",
        "                \"lengths1\": self.lengths[idx1],\n",
        "                \"timings2\": self.timings[idx2],\n",
        "                \"lengths2\": self.lengths[idx2]\n",
        "                }\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1VVttosJrUr"
      },
      "source": [
        "This implementation works just fine, however there is a big issue: we are explicitly storing all the dataset in memory, and given the size of our dataset, this will definitily lead to a full occupation of the RAM and therefore to an error.\n",
        "\n",
        "If you want, you can try (even if I do not suggest you to do that):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS0dvO-bYq1K"
      },
      "outputs": [],
      "source": [
        "#train_siamese = SiameseDataset(train_dataset,char_vocab)\n",
        "#val_siamese = SiameseDataset(val_dataset,char_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dasf6QhqKpDU"
      },
      "source": [
        "####4.1.3. Lazy implementation\n",
        "\n",
        "The solution to this issue, is to implement our Dataset in a lazy way, meaning that we load the data into memory only when it is actually requested.\n",
        "\n",
        "Now, our dataset will only consider which are the files that corresponds to the requested data, and load these files on the fly.\n",
        "\n",
        "So, this is the lazy implementation, in which, instead of the classic Dataset class, I used the IterableDataset class instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7IhOGkOepjS"
      },
      "outputs": [],
      "source": [
        "#@title Lazy dataset\n",
        "class LazySiameseDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, users_list : List[int], vocab : Dict[str,int]):\n",
        "        self.vocab = vocab\n",
        "        self.users_list = users_list\n",
        "        # total number of samples (15 samples per user)\n",
        "        self.samples_num: int = 15 * len(users_list)\n",
        "        # number of possible couples\n",
        "        self.comb_num: int = self.samples_num * (self.samples_num-1) // 2\n",
        "    \n",
        "    def __iter__(self) -> Tuple[int,int]:\n",
        "        return map(self.load_couple,map(self.internal_index_2_combination, range(self.comb_num)))\n",
        "\n",
        "    def internal_index_2_combination(self,idx : int) -> Tuple[int,int]:\n",
        "        return index_2_combination(idx, self.samples_num, self.comb_num)\n",
        "\n",
        "    def load_item(self, idx : int) -> Tuple[torch.Tensor,torch.Tensor,torch.Tensor]:\n",
        "        '''\n",
        "        Load a single sample (the one with index idx)\n",
        "        '''\n",
        "        # file in which the sample is\n",
        "        file_idx : int = idx // 15\n",
        "        # row of the file in which the sample is\n",
        "        row_idx : int= idx % 15\n",
        "        # read the file\n",
        "        user_id : int = self.users_list[file_idx]\n",
        "        df : pd.DataFrame = pd.read_csv(f\"data/Keystrokes_processed/{user_id}_keystrokes.txt\",\n",
        "                                sep=\",\",\n",
        "                                names = column_names,\n",
        "                                header=None,\n",
        "                                encoding = \"ISO-8859-1\",\n",
        "                                )\n",
        "        # get the row\n",
        "        row = df.iloc[row_idx]\n",
        "        # convert the row into tensors\n",
        "        ground_truth : torch.Tensor = torch.tensor(row.PARTICIPANT_ID)\n",
        "        timings : torch.Tensor = string_to_tensor(row.TIMINGS, self.vocab)\n",
        "        length : torch.Tensor = torch.tensor(timings.shape[0])\n",
        "        return ground_truth, timings, length\n",
        "    \n",
        "    def load_couple(self, indexes: Tuple[int,int]) -> Dict[str,torch.Tensor]:\n",
        "        '''\n",
        "        Load 2 samples whose indexes are given in the input tuple\n",
        "        '''\n",
        "        g1, t1, l1 = self.load_item(indexes[0])\n",
        "        g2, t2, l2 = self.load_item(indexes[1])\n",
        "        return {\n",
        "            \"genuine\" : g1 == g2,\n",
        "            \"timings1\": t1,\n",
        "            \"length1\" : l1,\n",
        "            \"timings2\": t2,\n",
        "            \"length2\" : l2\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfgK_YgeMFiN"
      },
      "source": [
        "The only little issue whit the lazy implementation is that, when the dataset is wrapped into a DataLoader, the batches of data cannot be shuffled; this property is something that we like in the training set, to avoid to give the model a bias of the order of the samples.\n",
        "\n",
        "In order to fix this, the training set is wrapped in the [ShuffleDataset](https://discuss.pytorch.org/t/how-to-shuffle-an-iterable-dataset/64130/6) class, that does the trick by shuffling just a given number of samples (the buffer size of this class):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oVrtIwZZkN9P"
      },
      "outputs": [],
      "source": [
        "#@title Shuffle Dataset wrapper\n",
        "class ShuffleDataset(torch.utils.data.IterableDataset):\n",
        "  def __init__(self, dataset : torch.utils.data.IterableDataset , buffer_size : int):\n",
        "    super().__init__()\n",
        "    self.dataset = dataset\n",
        "    self.buffer_size = buffer_size\n",
        "\n",
        "  def __iter__(self):\n",
        "    shufbuf = []\n",
        "    try:\n",
        "      dataset_iter = iter(self.dataset)\n",
        "      for i in range(self.buffer_size): # iterate over the dataset for buffer times\n",
        "        shufbuf.append(next(dataset_iter)) # append the data to the shuffle buffer\n",
        "    except:\n",
        "      self.buffer_size = len(shufbuf)\n",
        "\n",
        "    try:\n",
        "      while True:\n",
        "        try:\n",
        "          item = next(dataset_iter) # take a new sample\n",
        "          evict_idx = random.randint(0, self.buffer_size - 1) # take a random index\n",
        "          yield shufbuf[evict_idx] # return a random element of the shuffle buffer\n",
        "          shufbuf[evict_idx] = item # substitute the element with new one\n",
        "        except StopIteration: # when the iterator ends\n",
        "          break\n",
        "      while len(shufbuf) > 0: # return the remaining element of the shuffle buffer\n",
        "        yield shufbuf.pop()\n",
        "    except GeneratorExit:\n",
        "      pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZg0CRcbp_rf"
      },
      "source": [
        "However, even though this solution perfectly works, we have got another issue; indeed, while before we had a space problem, now we also have to consider the time issue.\n",
        "\n",
        "Since our training set is composed of $68*10^3$ users, and each user has 15 samples belonging to him, we have actually $15*68*10^3= 1,02 * 10^6$ samples (so a million of them). If we now consider all the possible couples, our model will have to be trained on $\\frac{1,02 * 10^6 * (1,02*10^6 - 1)}{2} = 520.199.490.000 \\approx 520 * 10^9$ examples.\n",
        "\n",
        "Train a model for 520 billion examples is just not doable (at least here in Colab). We can solve this problem in 2 ways:\n",
        "\n",
        "1. Reduce the number of users.\n",
        "2. Do not consider all the possible couples but for each sample of the dataset pick a random \"twin\" to be trained with.\n",
        "\n",
        "With the second solution, which is implemented in the class below, we decrease the number of training step from 520 billion to 1 million."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GITC_195sKBV"
      },
      "outputs": [],
      "source": [
        "#@title Random Lazy dataset\n",
        "class RandomLazySiameseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, users_list : List[int], vocab : Dict[str,int], dataset : pd.DataFrame, max_len : int = None):\n",
        "        self.vocab = vocab\n",
        "        self.users_list = users_list\n",
        "        self.dataset = dataset\n",
        "        # total number of samples (15 samples per user)\n",
        "        self.samples_num: int = 15 * len(users_list)\n",
        "        self.len = max_len if max_len is not None else self.samples_num\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx : int) -> Dict[str,torch.Tensor]:\n",
        "        # whether to pick a genuine or a false twin\n",
        "        pick_genuine = bool(random.randint(0,1)) \n",
        "\n",
        "        # we want a genuine couple\n",
        "        if pick_genuine:\n",
        "            sample_idx = idx % 15\n",
        "            twin_idx = sample_idx\n",
        "            # sample until you pick a different twin than itself\n",
        "            while twin_idx == sample_idx:\n",
        "                twin_idx = random.randint(0,14)\n",
        "            final_idx = (idx - sample_idx) + twin_idx\n",
        "        # we want a non-genuine couple\n",
        "        else:\n",
        "            # since we have only 14 out of 1020000 possibility of picking a genuine\n",
        "            # we do not really care of not considering them in the sampling\n",
        "            final_idx = idx\n",
        "            while final_idx == idx:\n",
        "                final_idx = random.randint(0,self.samples_num - 1)\n",
        "        return self.load_couple((idx,final_idx))\n",
        "\n",
        "    def load_item(self, idx : int) -> Tuple[torch.Tensor,torch.Tensor,torch.Tensor]:\n",
        "        file_idx : int = idx // 15\n",
        "        row_idx : int= idx % 15\n",
        "        user_id : int = self.users_list[file_idx]\n",
        "        df = self.dataset[self.dataset.PARTICIPANT_ID == user_id]\n",
        "        row = df.iloc[row_idx]\n",
        "        ground_truth : torch.Tensor = torch.tensor(row.PARTICIPANT_ID)\n",
        "        timings : torch.Tensor = string_to_tensor(row.TIMINGS, self.vocab)\n",
        "        length : torch.Tensor = torch.tensor(timings.shape[0])\n",
        "        return ground_truth, timings, length\n",
        "    \n",
        "    def load_couple(self, indexes: Tuple[int,int]) -> Dict[str,torch.Tensor]:\n",
        "        g1, t1, l1 = self.load_item(indexes[0])\n",
        "        g2, t2, l2 = self.load_item(indexes[1])\n",
        "        return {\n",
        "            \"genuine\" : g1 == g2,\n",
        "            \"timings1\": t1,\n",
        "            \"length1\" : l1,\n",
        "            \"timings2\": t2,\n",
        "            \"length2\" : l2\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Yl5AvTOQhj"
      },
      "source": [
        "####4.1.3. Final wrapping into DataLoaders\n",
        "Now, we just have to create our datasets and wrap them into dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpd6-RlqOQHx",
        "outputId": "3f09ee0a-97f1-49ba-ee4c-5bf1a1a4d50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 405/405 [00:00<00:00, 5221.37it/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Dataset instantiation\n",
        "\n",
        "# the list of the users for each dataset\n",
        "train_users = sorted(set(train_dataset.PARTICIPANT_ID))\n",
        "val_users = sorted(set(val_dataset.PARTICIPANT_ID))\n",
        "\n",
        "# the training set will be shuffled\n",
        "#train_siamese = ShuffleDataset(LazySiameseDataset(train_users,char_vocab), buffer_size = batch_size)\n",
        "train_siamese = RandomLazySiameseDataset(train_users,char_vocab, train_dataset, max_len = train_batches_per_epoch * batch_size)\n",
        "# for the validation it is not necessary\n",
        "val_siamese = SiameseDataset(val_dataset,char_vocab)\n",
        "#val_siamese = LazySiameseDataset(val_users,char_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSU7eIzWRb18"
      },
      "source": [
        "In order to batch the data into dataloaders, we are going to have to pad the shorter sequences to make them have the same lenght of the longer ones.\n",
        "\n",
        "This is done in the so-called collate function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "02QlNG8tRt_a"
      },
      "outputs": [],
      "source": [
        "#@title Collate function\n",
        "def collate_fn(batch : List[Dict[str,torch.Tensor]]) -> Dict[str,torch.Tensor]:\n",
        "    batch_out : Dict[str,torch.Tensor] = dict()\n",
        "    timings1 : List[torch.Tensor] = list()\n",
        "    timings2 : List[torch.Tensor] = list()\n",
        "    genuine : torch.Tensor = torch.zeros(len(batch))\n",
        "    lengths1 : torch.Tensor = torch.zeros_like(genuine)\n",
        "    lengths2 : torch.Tensor = torch.zeros_like(genuine)\n",
        "    for i,sample in enumerate(batch):\n",
        "        timings1.append(sample[\"timings1\"])\n",
        "        timings2.append(sample[\"timings2\"])\n",
        "        lengths1[i] = sample['length1']\n",
        "        lengths2[i] = sample['length2']\n",
        "        genuine[i] = sample['genuine']\n",
        "    \n",
        "    batch_out[\"genuine\"] = genuine\n",
        "    batch_out[\"lengths1\"] = lengths1\n",
        "    batch_out[\"lengths2\"] = lengths2\n",
        "    batch_out[\"timings1\"] = torch.nn.utils.rnn.pad_sequence(timings1, batch_first = True)\n",
        "    batch_out[\"timings2\"] = torch.nn.utils.rnn.pad_sequence(timings2, batch_first = True)\n",
        "\n",
        "    return batch_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SswjddpKfVot"
      },
      "outputs": [],
      "source": [
        "#@title DataLoaders instantiation\n",
        "#train_dl = torch.utils.data.DataLoader(train_siamese,batch_size = batch_size, collate_fn = collate_fn)\n",
        "#train_dl = torch.utils.data.DataLoader(train_siamese,batch_size = batch_size, collate_fn = collate_fn, shuffle = True)\n",
        "#val_dl = torch.utils.data.DataLoader(val_siamese,batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAbszb8tzxTq"
      },
      "source": [
        "Let's wrap our datasets into a PytorchLightning DataModule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OxvQsC47zx5V"
      },
      "outputs": [],
      "source": [
        "#@title Lightning Datamodule\n",
        "class KeystrokeDataModule(pl.LightningDataModule):\n",
        "    def __init__(self,\n",
        "                 train_set : torch.utils.data.DataLoader,\n",
        "                 val_set : torch.utils.data.DataLoader):\n",
        "        super().__init__()\n",
        "        self.train_set = train_set\n",
        "        self.val_set = val_set\n",
        "    \n",
        "    def train_dataloader(self) -> torch.utils.data.DataLoader:\n",
        "        return torch.utils.data.DataLoader(self.train_set,\n",
        "                                           batch_size = batch_size,\n",
        "                                           collate_fn = collate_fn, \n",
        "                                           shuffle = True,\n",
        "                                           num_workers = 4)\n",
        "\n",
        "    def val_dataloader(self) -> torch.utils.data.DataLoader:\n",
        "        return torch.utils.data.DataLoader(self.val_set,\n",
        "                                           batch_size = batch_size,\n",
        "                                           num_workers = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2dPwHtNVXq9"
      },
      "source": [
        "###4.2. Deep learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgLQRF9Nfab-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Contrastive loss\n",
        "def contrastive_loss(distances : torch.Tensor, genuine : torch.Tensor, alpha : float = 1.5) -> torch.Tensor:\n",
        "        zero = torch.tensor(0)\n",
        "        genuine_loss = genuine * (distances**2) / 2\n",
        "        impostor_loss = (1 - genuine) * ((torch.maximum(zero,alpha - distances))**2) / 2\n",
        "        return (impostor_loss + genuine_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lOVysXdEYgQ9"
      },
      "outputs": [],
      "source": [
        "#@title Generic lightning model\n",
        "class SiameseModel(pl.LightningModule):\n",
        "    def __init__(self,alpha : float = 1.5) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # activation function\n",
        "        self.activation = torch.nn.functional.relu\n",
        "\n",
        "        # loss hyperparam\n",
        "        self.alpha = alpha\n",
        "   \n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def single_forward(self,\n",
        "                       timings: torch.Tensor,\n",
        "                       lenghts: torch.Tensor) -> torch.Tensor:\n",
        "        # Implementation dependent on the chosen model\n",
        "        pass\n",
        "\n",
        "    def forward(self,\n",
        "                timings1: torch.Tensor,\n",
        "                lengths1: torch.Tensor,\n",
        "                timings2: torch.Tensor,\n",
        "                lengths2: torch.Tensor,\n",
        "                genuine: torch.Tensor\n",
        "                ) -> torch.Tensor:\n",
        "\n",
        "        o1 = self.single_forward(timings1,lengths1)\n",
        "        o2 = self.single_forward(timings2,lengths2)\n",
        "\n",
        "        euclidean_distance = (((o1 - o2)**2).sum(dim = 1)) ** 1/2\n",
        "\n",
        "        return contrastive_loss(euclidean_distance,genuine, alpha = self.alpha)\n",
        "\n",
        "    def step(self, batch) -> torch.Tensor:\n",
        "        loss : torch.Tensor = self(**batch)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx) -> torch.Tensor:\n",
        "        return self.step(train_batch)\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx) -> torch.Tensor:\n",
        "        return self.step(val_batch)\n",
        "    \n",
        "    def log_metrics(self, loss: float, type: str):\n",
        "        self.log(f'{type}_loss', loss)\n",
        "        self.log(f'epoch', float(self.current_epoch))\n",
        "\n",
        "    def training_epoch_end(self, outputs) -> None:\n",
        "        loss = sum([x[\"loss\"] for x in outputs]) / len(outputs)\n",
        "        self.log_metrics(loss.item(), 'train')\n",
        "        return super().training_epoch_end(outputs)\n",
        "\n",
        "    def validation_epoch_end(self, outputs) -> None:\n",
        "        loss = sum(outputs) / len(outputs)\n",
        "        self.log_metrics(loss.item(), 'val')\n",
        "        return super().validation_epoch_end(outputs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84JOlJMFVikD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title LSTM Model\n",
        "class KeystrokeLSTM(SiameseModel):\n",
        "    def __init__(self,\n",
        "                 embedding_dim: int,\n",
        "                 time_dim: int,\n",
        "                 hidden_size: int,\n",
        "                 output_size : int,\n",
        "                 dropout : float = 0,\n",
        "                 alpha : float = 1.5,\n",
        "                 bidirectional : bool = False,\n",
        "                 lstm_layers: int = 1) -> None:\n",
        "        super().__init__(alpha = alpha)\n",
        "\n",
        "        # embedding layer\n",
        "        self.key_emb = torch.nn.Embedding(num_embeddings=len(char_vocab),\n",
        "                                          embedding_dim=embedding_dim,\n",
        "                                          padding_idx=char_vocab[PAD_KEY])\n",
        "\n",
        "        # linear projection of the time features\n",
        "        self.time_features = torch.nn.Linear(2, time_dim)\n",
        "\n",
        "        # lstm\n",
        "        self.bidirectional = bidirectional\n",
        "        self.d = 2 if bidirectional else 1\n",
        "        self.lstm = torch.nn.LSTM(input_size=embedding_dim+time_dim,\n",
        "                                  hidden_size=hidden_size,\n",
        "                                  num_layers=lstm_layers,\n",
        "                                  bidirectional=bidirectional)\n",
        "        # linear layer\n",
        "        self.linear = torch.nn.Linear(in_features=self.d*hidden_size,\n",
        "                                      out_features=output_size)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = torch.nn.Dropout(p = dropout)\n",
        "        \n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def single_forward(self,\n",
        "                       timings: torch.Tensor,\n",
        "                       lengths: torch.Tensor) -> torch.Tensor:\n",
        "        \n",
        "        batch_size = lengths.shape[0]\n",
        "\n",
        "        emb = self.key_emb(timings[:,:,0].long())\n",
        "        timings = self.time_features(timings[:,:,1:])\n",
        "\n",
        "        x = torch.concat((emb, timings), dim=-1)\n",
        "\n",
        "        x = self.lstm(self.dropout(x))[0][torch.arange(batch_size), (lengths-1).long(), :]\n",
        "\n",
        "        x = self.linear(self.dropout(x))\n",
        "\n",
        "        x = self.activation(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Oa_R7LEn0jul"
      },
      "outputs": [],
      "source": [
        "#@title Transformer model\n",
        "class KeystrokeEncoder(SiameseModel):\n",
        "    def __init__(self,\n",
        "                 time_dim : int,\n",
        "                 embedding_dim : int,\n",
        "                 nhead : int = 8,\n",
        "                 dim_feedforward : int = 2048,\n",
        "                 dropout : float = 0.1,\n",
        "                 alpha : float = 1.5,\n",
        "                 num_layers: int = 6) -> None:\n",
        "        super().__init__(alpha = alpha)\n",
        "\n",
        "        # an encoder layer\n",
        "        encoder = torch.nn.TransformerEncoderLayer(d_model=time_dim + embedding_dim,\n",
        "                                                nhead = nhead,\n",
        "                                                dim_feedforward = dim_feedforward,\n",
        "                                                dropout = dropout,\n",
        "                                                batch_first = True)\n",
        "        # the encoder architecture\n",
        "        self.encoder = torch.nn.TransformerEncoder(encoder_layer = encoder, num_layers = num_layers)\n",
        "\n",
        "        # linear projection of the time features\n",
        "        self.time_features = torch.nn.Linear(2, time_dim)\n",
        "\n",
        "        # embedding of the key\n",
        "        self.key_emb = torch.nn.Embedding(num_embeddings=len(char_vocab),\n",
        "                                          embedding_dim=embedding_dim,\n",
        "                                          padding_idx=char_vocab[PAD_KEY])\n",
        "        \n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def single_forward(self,\n",
        "                       timings: torch.Tensor,\n",
        "                       lengths: torch.Tensor) -> torch.Tensor:\n",
        "        \n",
        "        batch_size = lengths.shape[0]\n",
        "        max_len = timings.shape[1]\n",
        "\n",
        "        emb = self.key_emb(timings[:,:,0].long())\n",
        "        timings = self.time_features(timings[:,:,1:])\n",
        "\n",
        "        x = torch.concat((emb, timings), dim=-1)\n",
        "\n",
        "        mask = torch.logical_not(torch.arange(max_len, device = self.device)[None, :] < lengths[:, None])\n",
        "        \n",
        "        x = self.encoder(x, src_key_padding_mask = mask)[torch.arange(batch_size), (lengths-1).long(), :]\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRQ6ZBIS2tg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "48ba93c8-9269-48e0-bc54-06ee91ee147f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230126_152026-145p996m</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ale99/FreeKeystrokeDynamics/runs/145p996m\" target=\"_blank\">dazzling-cake-86</a></strong> to <a href=\"https://wandb.ai/ale99/FreeKeystrokeDynamics\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/ale99/FreeKeystrokeDynamics\" target=\"_blank\">https://wandb.ai/ale99/FreeKeystrokeDynamics</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/ale99/FreeKeystrokeDynamics/runs/145p996m\" target=\"_blank\">https://wandb.ai/ale99/FreeKeystrokeDynamics/runs/145p996m</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#login\n",
        "wandb.login\n",
        "wandb.init(project='FreeKeystrokeDynamics', entity='ale99')#, id =\"li4jgm0b\", resume = \"must\" )\n",
        "wandb.run.name = run_name\n",
        "\n",
        "# lightning logger\n",
        "logger = pl.loggers.WandbLogger(name=run_name, project='FreeKeystrokeDynamics')\n",
        "\n",
        "# metrics definitions\n",
        "wandb.define_metric('epoch')\n",
        "wandb.define_metric('train_loss',step_metric='epoch')\n",
        "wandb.define_metric('val_loss',step_metric='epoch')\n",
        "\n",
        "#config of the run\n",
        "wandb.config.batch_size = batch_size\n",
        "wandb.config.val_perc = perc\n",
        "wandb.config.train_batches_per_epoch = train_batches_per_epoch\n",
        "wandb.config.train_size = train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NybKlnChqE2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45efb72a-81c5-4c22-8f29-9c59d14030ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Keystroke\n"
          ]
        }
      ],
      "source": [
        "# Checkpoint to save the model with the lowest validation loss\n",
        "from pytorch_lightning import callbacks\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive/MyDrive/Keystroke\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(\"checkpoints/\",\n",
        "                                       monitor=\"val_loss\",\n",
        "                                       mode=\"min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T-GI76IS8Cz"
      },
      "outputs": [],
      "source": [
        "pl.seed_everything(seed)\n",
        "datamodule = KeystrokeDataModule(train_siamese,val_siamese)\n",
        "#net = KeystrokeLSTM(time_dim = 100, embedding_dim = 100, hidden_size = 128, output_size = 200, dropout = 0.1, lstm_layers = 2, bidirectional = True)\n",
        "net = KeystrokeEncoder(time_dim = 100, embedding_dim = 100, dim_feedforward = 128, num_layers = 6, alpha = 2)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=50,\n",
        "                         accelerator='gpu',\n",
        "                         devices=1,\n",
        "                         logger=logger,\n",
        "                         callbacks=[checkpoint])\n",
        "\n",
        "trainer.fit(model=net, datamodule=datamodule)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVCtMfloXJVY"
      },
      "source": [
        "##5. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj5uUFZr7U_T"
      },
      "source": [
        "###5.1 Qualitative Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we find n random users never used at training time"
      ],
      "metadata": {
        "id": "GOJ7k_-Um-zm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5aCgcGHisIv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "all_users : List[str] = sorted(os.listdir(\"../../../data/Keystrokes_processed/\"))\n",
        "train_users : List[str] = sorted(set(train_dataset.PARTICIPANT_ID))\n",
        "n_users : int = 6 #@param{type: \"integer\"}\n",
        "test_users = []\n",
        "while len(test_users) < n_users:\n",
        "    i = random.randint(train_size + 1, len(all_users)-1)\n",
        "    if all_users[i] not in train_users or \"keystroke\" not in all_users[i]:\n",
        "        test_users.append((all_users[i],False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the samples of the users\n",
        "test_df = []\n",
        "for user,manual in test_users:\n",
        "    df = pd.read_csv(f\"../../../data/Keystrokes_processed/{user}\",\n",
        "                 sep=\",\",\n",
        "                 names = column_names,\n",
        "                 header=None,\n",
        "                 encoding = \"ISO-8859-1\",\n",
        "                )\n",
        "    test_df.append((df,manual))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YCLb7Kr2k9TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M7zoRNtJ7RAm"
      },
      "outputs": [],
      "source": [
        "#@title Load the model from the checkpoint\n",
        "network_type : str = \"Transformer\" #@param[\"Transformer\",\"LSTM\"]\n",
        "checkpoint_name : str = \"(14)Transformer(alpha2)\" #@param{type:\"string\"}\n",
        "if network_type == \"Transformer\":\n",
        "    pretrained_net = KeystrokeEncoder.load_from_checkpoint(f\"checkpoints/{checkpoint_name}.ckpt\")\n",
        "    # retrieve hyperparameters of the model\n",
        "    time_dim = pretrained_net.time_features.out_features\n",
        "    emb_dim = pretrained_net.key_emb.embedding_dim\n",
        "    num_layers = len(pretrained_net.encoder.layers)\n",
        "    x : torch.nn.TransformerEncoderLayer = pretrained_net.encoder.layers[0]\n",
        "    dropout = x.dropout.p\n",
        "    dim_feedforward = x.linear1.out_features\n",
        "    num_heads = x.self_attn.num_heads\n",
        "    # initialize a random net with the same hyperparam\n",
        "    random_net = KeystrokeEncoder(time_dim,\n",
        "                                  emb_dim,\n",
        "                                  num_heads,\n",
        "                                  dim_feedforward,\n",
        "                                  dropout,\n",
        "                                  pretrained_net.alpha,\n",
        "                                  num_layers)\n",
        "\n",
        "else:\n",
        "    pretrained_net = KeystrokeLSTM.load_from_checkpoint(f\"checkpoints/{checkpoint_name}.ckpt\")\n",
        "    bidirectional = pretrained_net.bidirectional \n",
        "    dropout = pretrained_net.dropout.p\n",
        "    emb_dim = pretrained_net.key_emb.embedding_dim\n",
        "    time_dim = pretrained_net.time_features.out_features\n",
        "    hidden_size = pretrained_net.lstm.hidden_size\n",
        "    output_size = pretrained_net.linear.out_features\n",
        "    num_layers = pretrained_net.lstm.num_layers\n",
        "    random_net = KeystrokeLSTM(embedding_dim = emb_dim,\n",
        "                               time_dim = time_dim,\n",
        "                               hidden_size = hidden_size,\n",
        "                               output_size = output_size,\n",
        "                               dropout = dropout,\n",
        "                               bidirectional = bidirectional,\n",
        "                               lstm_layers = num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cpgAFzquaAKM"
      },
      "outputs": [],
      "source": [
        "#@title Utility functions\n",
        "def compute_metrics(sample: List[Tuple[str, float, float]], vocab : Dict[str,int]) -> List[Tuple[int, float, float]]:\n",
        "    '''\n",
        "    Given the timings of a recorded sentence, it computes for each key:\n",
        "    - the dwell time, the time between a key press and its release\n",
        "    - waiting time, time between the previous key is released and the actual is pressed\n",
        "\n",
        "    Other metrics can be computed but are ignored since are a combination of the two above:\n",
        "    - releasing interval, the time between the previous key is released and the actual one is released (NOT USED since it is basically dwell time + waiting time)\n",
        "    - pressing interval, time between pressing of the previous key and pressing of the current one (NOT USED since it is prev dwell time + waiting time)\n",
        "    - double typing time, time between the pressing of the previous key and the releasing of the current one (NOT USED since it is dwell time + prev dwell time + waiting time)\n",
        "\n",
        "    '''\n",
        "    output = list()\n",
        "    for i, (key, press_time, release_time) in enumerate(sample):\n",
        "        key = key.lower()\n",
        "        if \"key\" in key:\n",
        "            key = key.split(\":\")[0].split(\".\")[1]\n",
        "            key = key if key != \"space\" else \" \"\n",
        "            if \"shift\" in key:\n",
        "                key = \"shift\"\n",
        "        dwell_time = round(release_time - press_time, 5)\n",
        "        if i == 0:\n",
        "            waiting_time = 0\n",
        "            # releasing_interval = 0\n",
        "            # pressing_interval = 0\n",
        "            # double_typing_time = 0\n",
        "        else:\n",
        "            _, prev_press_time, prev_release_time = sample[i-1]\n",
        "            waiting_time = round(press_time - prev_release_time, 5)\n",
        "            # releasing_interval = release_time - prev_release_time\n",
        "            # pressing_interval = press_time - prev_press_time\n",
        "            # double_typing_time = release_time - prev_press_time\n",
        "        output.append((vocab.get(key,vocab[UNK_KEY]),\n",
        "                       dwell_time,\n",
        "                       waiting_time,))\n",
        "\n",
        "    return output\n",
        "\n",
        "def pd_conversion(df: pd.DataFrame, vocab : Dict[str,int]) -> pd.DataFrame:\n",
        "    '''\n",
        "    Given a dataframe, this function converts it into another one\n",
        "    that has the timing metrics instead of the relative time of the events\n",
        "    '''\n",
        "    columns = [\"Subject\", \"Date\", \"Sentence\", \"Timings\"]\n",
        "    data = list()\n",
        "    for i in range(df.shape[0]):\n",
        "        # subject,date,sentence\n",
        "        sub, date, sentence = df.iloc[i][:3]\n",
        "        row = [sub, date, sentence]\n",
        "        timings_row = df.iloc[i][3]\n",
        "        if type(timings_row) == list:\n",
        "            timings_row = [(str(k), p, r) for k, p, r in timings_row]\n",
        "\n",
        "        timings = compute_metrics(timings_row if type(timings_row) == list\n",
        "                                  else string_to_seq(df.iloc[i][3]), vocab)\n",
        "        row.append(timings)\n",
        "        data.append(row)\n",
        "\n",
        "    return pd.DataFrame(data=data, columns=columns)\n",
        "\n",
        "def df_to_tensor(df: pd.DataFrame, vocab: Dict[str, int], manual_data: bool = True) -> Tuple[List[str],Dict[str, torch.Tensor]]:\n",
        "    '''\n",
        "    This function converts a dataframe into a list containing tuples (name, dict of tensors) where dict of\n",
        "    tensors can be directly fed to the model.\n",
        "    df is the pandas dataframe to convert, vocab is the character vocabulary while \n",
        "    manual data tells if the dataframe contains data acquired with pynput or it's the same kind\n",
        "    of data used for training.\n",
        "    '''\n",
        "    labels : List[str] = list()\n",
        "    df_size = len(df)\n",
        "    if manual_data:\n",
        "        def internal_metrics(sample):\n",
        "            return compute_metrics(sample,vocab)\n",
        "        dfp = pd_conversion(df, vocab)\n",
        "        in_dict = dict()\n",
        "        timings = df.Timings.apply(string_to_seq).apply(internal_metrics)\n",
        "        max_len = len(max(timings, key = lambda x : len(x)))\n",
        "        labels = list(df.Subject)\n",
        "        in_dict[\"lengths\"] = torch.zeros(df_size)\n",
        "        in_dict[\"timings\"] = torch.zeros(df_size, max_len,3)\n",
        "        for i in range(len(dfp)):\n",
        "            ti = timings.iloc[i]\n",
        "            l = len(ti)\n",
        "            in_dict[\"lengths\"][i] = l\n",
        "            in_dict[\"timings\"][i,:l,:] = torch.tensor(ti)\n",
        "    else:\n",
        "        in_dict = dict()\n",
        "        timings = df.TIMINGS.apply(string_to_timings)\n",
        "        max_len = len(max(timings, key = lambda x : len(x)))\n",
        "        labels = list(df.PARTICIPANT_ID)\n",
        "        in_dict[\"lengths\"] = torch.zeros(df_size)\n",
        "        in_dict[\"timings\"] = torch.zeros(df_size, max_len,3)\n",
        "        for i in range(len(df)):\n",
        "            ti = timings.iloc[i]\n",
        "            l = len(ti)\n",
        "            in_dict[\"timings\"][i,:l,:] = torch.tensor([ [vocab.get(key,vocab[UNK_KEY]),dt,wt] for key,keycode,dt,wt in ti])\n",
        "            in_dict[\"lengths\"][i] = l\n",
        "\n",
        "    return labels, in_dict\n",
        "\n",
        "def df_to_features(df: pd.DataFrame, vocab: Dict[str, int], model: torch.nn.Module, manual_data : bool = True) -> Tuple[List[str], List[torch.Tensor]]:\n",
        "    labels, in_dict = df_to_tensor(df, vocab, manual_data = manual_data)\n",
        "    model.eval()\n",
        "    features = model.single_forward(**in_dict)\n",
        "    return labels, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vODhVXu8vuSH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load a dataframe of manually taken data\n",
        "my_data = pd.read_csv(\"manual_data/Alessandro.csv\")\n",
        "test_df.append((my_data,True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTPfAWtJdv92",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Obtain the model features\n",
        "ground_truth, data = [], []\n",
        "p_data = []\n",
        "for df, manual in test_df:\n",
        "    g, d = df_to_features(df,char_vocab,pretrained_net,manual_data = manual)\n",
        "    _, pr = df_to_features(df,char_vocab,random_net,manual_data = manual)\n",
        "    ground_truth += g\n",
        "    data += d\n",
        "    p_data += pr\n",
        "\n",
        "# convert the features in numpy arrays\n",
        "data = [ x.detach().numpy() for x in data]\n",
        "p_data = [ x.detach().numpy() for x in p_data]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Project the features in 2d data with PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "data = pca.fit_transform(data)\n",
        "pca = PCA(n_components=2)\n",
        "p_data = pca.fit_transform(p_data)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "df7ZFmOiaeCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot the points\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "color_palette = mcolors.TABLEAU_COLORS if n_users <= 10 else mcolors.CSS4_COLORS\n",
        "colors = list(color_palette)\n",
        "color_vocab = { label:colors[i%len(colors)] for i,label in enumerate(set(ground_truth))}\n",
        "xs = [ x[0] for x in data ]\n",
        "xs_d = [ x[0] for x in p_data ]\n",
        "ys = [ x[1] for x in data ]\n",
        "l = []\n",
        "lg = []\n",
        "fig, axs = plt.subplots(1,2)\n",
        "fig.set_size_inches(18.5, 7.5)\n",
        "seen_labels = set()\n",
        "for i in range(len(ground_truth)):\n",
        "    o, = axs[1].plot(xs[i], ys[i], \"o\", color=color_palette[color_vocab[ground_truth[i]]])\n",
        "    o_p, = axs[0].plot(xs_d[i], ys[i], \"o\", color=color_palette[color_vocab[ground_truth[i]]])\n",
        "    if ground_truth[i] not in seen_labels:\n",
        "        l.append(o)\n",
        "        lg.append(ground_truth[i])\n",
        "        seen_labels.add(ground_truth[i])\n",
        "    #plt.text(xs[i], ys[i], ground_truth[i], fontsize=8)\n",
        "axs[0].set_title(\"Random net features\")\n",
        "axs[1].set_title(\"Trained net features\")\n",
        "axs[1].legend(l,\n",
        "           lg,\n",
        "           loc=(1.04, 0.5),\n",
        "           ncol=3,\n",
        "           fontsize=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "cellView": "form",
        "id": "JsbVxlBQdtvZ",
        "outputId": "9735c19c-4160-4a49-d0cd-78c655895d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1332x540 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.2 Quantitative testing"
      ],
      "metadata": {
        "id": "icKhIxr4yM4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size : int = 1000 #@param{type:\"integer\"}\n",
        "test_users = []\n",
        "i = train_size + 1\n",
        "# found the first test_size users not used in the training\n",
        "while len(test_users) < test_size:\n",
        "    if all_users[i] not in train_users or \"keystroke\" not in all_users[i]:\n",
        "        test_users.append((all_users[i],False))\n",
        "    i += 1\n",
        "\n",
        "# stack all of them into a pandas dataframe TODO deal with manual\n",
        "test_df = []\n",
        "for user,manual in test_users:\n",
        "    df = pd.read_csv(f\"../../../data/Keystrokes_processed/{user}\",\n",
        "                 sep=\",\",\n",
        "                 names = column_names,\n",
        "                 header=None,\n",
        "                 encoding = \"ISO-8859-1\",\n",
        "                )\n",
        "    test_df.append(df)\n",
        "\n",
        "test_df : pd.DataFrame = pd.concat(test_df)\n",
        "test_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "cellView": "form",
        "id": "sT0zIC84yQL2",
        "outputId": "0e917cb3-f103-44fd-eb29-655b28f71f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PARTICIPANT_ID  TEST_SECTION_ID  \\\n",
              "0          286689          3075839   \n",
              "1          286689          3075934   \n",
              "2          286689          3075921   \n",
              "3          286689          3075654   \n",
              "4          286689          3075692   \n",
              "\n",
              "                                            SENTENCE  \\\n",
              "0  Hence the importannce of the media bidding bat...   \n",
              "1   My husband Jeff and I are planning on attending.   \n",
              "2                 He did not say when that would be.   \n",
              "3  He extended Freudian theory into adolescence a...   \n",
              "4  Louis defensive backs should be able to match ...   \n",
              "\n",
              "                                          USER_INPUT  \\\n",
              "0  Hence the importannce of the media bidding bat...   \n",
              "1   My husband Jeff and I are planning to attending.   \n",
              "2                      He did not say that would be.   \n",
              "3  He extended Freudian theory into adolescence a...   \n",
              "4  Louis defensive backs should be able to match ...   \n",
              "\n",
              "                                             TIMINGS  \n",
              "0  Any[(\"SHIFT\", 16, 392, 0), (\"72\", missing, 136...  \n",
              "1  Any[(\"SHIFT\", 16, 328, 0), (\"77\", missing, 119...  \n",
              "2  Any[(\"SHIFT\", 16, 568, 0), (\"72\", missing, 104...  \n",
              "3  Any[(\"SHIFT\", 16, 256, 0), (\"72\", missing, 128...  \n",
              "4  Any[(\"SHIFT\", 16, 1680, 0), (\"76\", missing, 16...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aea3b47b-05e6-4a2d-b0b2-9c082d500516\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PARTICIPANT_ID</th>\n",
              "      <th>TEST_SECTION_ID</th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>USER_INPUT</th>\n",
              "      <th>TIMINGS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>286689</td>\n",
              "      <td>3075839</td>\n",
              "      <td>Hence the importannce of the media bidding bat...</td>\n",
              "      <td>Hence the importannce of the media bidding bat...</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 392, 0), (\"72\", missing, 136...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>286689</td>\n",
              "      <td>3075934</td>\n",
              "      <td>My husband Jeff and I are planning on attending.</td>\n",
              "      <td>My husband Jeff and I are planning to attending.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 328, 0), (\"77\", missing, 119...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>286689</td>\n",
              "      <td>3075921</td>\n",
              "      <td>He did not say when that would be.</td>\n",
              "      <td>He did not say that would be.</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 568, 0), (\"72\", missing, 104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>286689</td>\n",
              "      <td>3075654</td>\n",
              "      <td>He extended Freudian theory into adolescence a...</td>\n",
              "      <td>He extended Freudian theory into adolescence a...</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 256, 0), (\"72\", missing, 128...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>286689</td>\n",
              "      <td>3075692</td>\n",
              "      <td>Louis defensive backs should be able to match ...</td>\n",
              "      <td>Louis defensive backs should be able to match ...</td>\n",
              "      <td>Any[(\"SHIFT\", 16, 1680, 0), (\"76\", missing, 16...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aea3b47b-05e6-4a2d-b0b2-9c082d500516')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aea3b47b-05e6-4a2d-b0b2-9c082d500516 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aea3b47b-05e6-4a2d-b0b2-9c082d500516');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,df : pd.DataFrame, vocab : Dict[str,int]):\n",
        "        self.vocab = vocab\n",
        "        self.data = df\n",
        "        self.len = len(self.data)\n",
        "    \n",
        "    def __getitem__(self,idx : int) -> Dict[str,Any]:\n",
        "        sample = self.data.iloc[idx]\n",
        "        t = string_to_tensor(sample.TIMINGS, self.vocab)\n",
        "        return { \"label\": sample.PARTICIPANT_ID, \"timings\": t, \"lengths\" : len(t) }\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return self.len\n",
        "\n",
        "def single_collate(batch : List[Dict[str,Any]]):\n",
        "    batch_size = len(batch)\n",
        "    batch_out = dict()\n",
        "    batch_out[\"lengths\"] = torch.zeros(batch_size)\n",
        "    max_len = max([ b[\"lengths\"] for b in batch])\n",
        "    batch_out[\"timings\"] = torch.zeros(batch_size,max_len,3)\n",
        "    batch_out[\"labels\"] = list()\n",
        "    for i,sample in enumerate(batch):\n",
        "        batch_out[\"lengths\"][i] = sample[\"lengths\"]\n",
        "        batch_out[\"timings\"][i,:sample[\"lengths\"],:] = sample[\"timings\"]\n",
        "        batch_out[\"labels\"].append(sample[\"label\"])\n",
        "    return batch_out\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "lqtp4_HHFh1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = TestDataset(test_df,char_vocab)\n",
        "test_dl = torch.utils.data.DataLoader(test_set, batch_size = 32, shuffle = False, collate_fn = single_collate)\n",
        "next(iter(test_dl))"
      ],
      "metadata": {
        "id": "rfTiBdePGL0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth, data = df_to_features(test_df,char_vocab,pretrained_net,manual_data = False)"
      ],
      "metadata": {
        "id": "8Px7Rby_y8QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "w2eV_dGwz65Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxj4itdABLtk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xeOJM1oapywQ",
        "oD0bmEN6oCCp",
        "cm81XjjS20MP",
        "XfR97VN4yhIm",
        "q42a4zqOhaez",
        "5oyIm8ILEZSC",
        "vH7Fvl8CIwbL"
      ],
      "authorship_tag": "ABX9TyPZjXufOxUmwc0hJiy1TcTG",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}